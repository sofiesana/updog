{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone as fo\n",
    "from ImageObjectExtractor import ImageObjectExtractor\n",
    "from utils import get_image\n",
    "from ImageWithTransplantedObjects import ImageWithTransplantedObjects\n",
    "from ExtractedObject import ExtractedObject\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coco-2017-validation-1', 'coco-2017-validation-10', 'coco-2017-validation-2', 'coco-2017-validation-20', 'coco-2017-validation-3', 'testing']\n"
     ]
    }
   ],
   "source": [
    "# print available datasets\n",
    "print(fo.list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'C:\\Users\\sophi\\fiftyone\\coco-2017\\validation' if necessary\n",
      "Found annotations at 'C:\\Users\\sophi\\fiftyone\\coco-2017\\raw\\instances_val2017.json'\n",
      "Sufficient images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading existing dataset 'coco-2017-validation-10'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "dataset = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"segmentations\"],\n",
    "    max_samples = 10,\n",
    "    classes= 'elephant'\n",
    ")\n",
    "dataset.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a5a\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a5b\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a5c\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a60\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a61\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a62\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a65\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a66\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a67\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a68\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a69\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a6a\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a6b\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a6c\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a6d\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a6e\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a6f\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a71\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a72\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a73\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a76\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a77\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a78\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a79\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a7a\n",
      "Object too small, skipping id: 6793dc0f62eb64e2038d7a7b\n"
     ]
    }
   ],
   "source": [
    "for sample in dataset:\n",
    "    save_location = 'outputs'\n",
    "    obj_extract = ImageObjectExtractor(sample, save_location=save_location, object_log_file='outputs/extracted_objects_log.json', filter=True, filter_type=\"min\")\n",
    "    obj_extract.extract_objects()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_updog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
